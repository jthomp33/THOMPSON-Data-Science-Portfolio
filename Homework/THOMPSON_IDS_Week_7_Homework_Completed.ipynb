{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "# Load the housing dataset\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names) \n",
    "y = pd.Series(housing.target, name='med_house_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first five rows of the dataset are:\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n",
      "\n",
      "Feature names:\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "\n",
      "Missing values in each column:\n",
      "MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
      "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
      "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
      "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
      "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
      "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
      "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
      "\n",
      "           AveOccup      Latitude     Longitude  \n",
      "count  20640.000000  20640.000000  20640.000000  \n",
      "mean       3.070655     35.631861   -119.569704  \n",
      "std       10.386050      2.135952      2.003532  \n",
      "min        0.692308     32.540000   -124.350000  \n",
      "25%        2.429741     33.930000   -121.800000  \n",
      "50%        2.818116     34.260000   -118.490000  \n",
      "75%        3.282261     37.710000   -118.010000  \n",
      "max     1243.333333     41.950000   -114.310000  \n"
     ]
    }
   ],
   "source": [
    "#Part 1\n",
    "# Display the first five rows of the dataset (5 pts)\n",
    "print(\"The first five rows of the dataset are:\")\n",
    "print(X.head())\n",
    "\n",
    "# Print feature names and check for missing values (5 pts)\n",
    "print(\"\\nFeature names:\")\n",
    "print(X.columns.tolist())\n",
    "\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Generate summary statistics (10 pts)\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(X.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance:\n",
      "Mean Squared Error (MSE): 0.5559\n",
      "Root Mean Squared Error (RMSE): 0.7456\n",
      "R² Score: 0.5758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Split the dataset into training and test sets (80% training, 20% testing) (5 pts)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model on the unscaled data (5 pts)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (5 pts)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance (15 pts)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"Mean Squared Error (MSE): {MSE:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {RMSE:.4f}\")\n",
    "print(f\"R² Score: {R2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### What does the R² score tell us about model performance?\n",
    "The R² score, which is also called the coefficient of determination, allows us insight into how well the model calculates variance in the desired variable. An R² score of 0.5758 means that our model is only able to explain 57.58% of the variance in hosuehold income. While this suggests a moderate fit, there is still a large portion of variance that the model does not capturesuggesting that this dataset might have a non-linear relationship and be dependent on some other factors. Indisutry standard for acceptable models differ by industry, and because resal estate developers acknowledge the volatile anture of the market, this can be on th elow end of a reliable predictor of variance. \n",
    "\n",
    "#### Which features seem to have the strongest impact on predictions based on the model’s coefficients?\n",
    "To determine which features have the strongest impact, one can look at the model's coefficients. To do this I ran the code below to rank the maginitude of importance of each feature. The higher the absolute value, the hgiher the impact on the prediction, which seems to be Average Bedrooms and Median Income. The psitive and negatives indicate if it impacts it positvely or negatively, but the absoltely value determines the magnitude of the impact on predictions. \n",
    "\n",
    "#### How well do the predicted values match the actual values?\n",
    "The RMSE of 0.7456 provides an estimate of the average prediction error in the same scale as the target variable. This means that the predictions produced by this model are $74,560 as the unties are in 100,000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature  Coefficient\n",
      "3   AveBedrms     0.783145\n",
      "0      MedInc     0.448675\n",
      "7   Longitude    -0.433708\n",
      "6    Latitude    -0.419792\n",
      "2    AveRooms    -0.123323\n",
      "1    HouseAge     0.009724\n",
      "5    AveOccup    -0.003526\n",
      "4  Population    -0.000002\n"
     ]
    }
   ],
   "source": [
    "# Get feature names and their corresponding coefficients\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})\n",
    "\n",
    "# Sort features by absolute value of coefficient to see strongest impacts\n",
    "feature_importance['Abs_Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "feature_importance = feature_importance.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Display the sorted feature importance\n",
    "print(feature_importance[['Feature', 'Coefficient']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simplified Model Performance:\n",
      "Mean Squared Error (MSE): 0.7071\n",
      "Root Mean Squared Error (RMSE): 0.8409\n",
      "R² Score: 0.4604\n"
     ]
    }
   ],
   "source": [
    "# Select the three chosen features\n",
    "selected_features = ['AveBedrms', 'MedInc', 'Longitude']\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Split into training and test sets (same 80/20 split)\n",
    "X_train_sel, X_test_sel, y_train_sel, y_test_sel = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a new linear regression model\n",
    "model_sel = LinearRegression()\n",
    "model_sel.fit(X_train_sel, y_train_sel)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_sel = model_sel.predict(X_test_sel)\n",
    "\n",
    "# Compute new performance metrics\n",
    "MSE_sel = mean_squared_error(y_test_sel, y_pred_sel)\n",
    "RMSE_sel = np.sqrt(MSE_sel)\n",
    "R2_sel = r2_score(y_test_sel, y_pred_sel)\n",
    "\n",
    "print(\"\\nSimplified Model Performance:\")\n",
    "print(f\"Mean Squared Error (MSE): {MSE_sel:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {RMSE_sel:.4f}\")\n",
    "print(f\"R² Score: {R2_sel:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the three models Avg. Bedrooms, Income, and Longitude because they were shown to have the most influence on the predictions and I (wrongly) predicted that it would have more reliable results when it came to variance. It yielded the R² Score lower than the original, meaning that this model does capture some of the important relationships, at least eh most impactful ones, more of the variables povide a more compelte picture. I would not use the simplified model in practice because I would want a more accurate predictor which more coefficents is evidenced to lend itself to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m mse_scaled \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred_scaled)\n\u001b[0;32m     20\u001b[0m r2_scaled \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred_scaled)\n\u001b[1;32m---> 21\u001b[0m rmse_scaled \u001b[38;5;241m=\u001b[39m RMSE_sel(y_test, y_pred_sel)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mScaled Data Model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse_scaled\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler and apply it to the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Split the scaled data\n",
    "X_train_scaled, X_test_scaled, _, _ = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model on scaled data\n",
    "lin_reg_scaled = LinearRegression()\n",
    "lin_reg_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_scaled = lin_reg_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
    "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
    "rmse_scaled = RMSE_sel(y_test, y_pred_sel)\n",
    "\n",
    "print(\"\\nScaled Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_scaled:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_scaled:.2f}\")\n",
    "print(f\"R² Score: {r2_scaled:.2f}\")\n",
    "print(\"Model Coefficients (Scaled):\")\n",
    "print(pd.Series(lin_reg_scaled.coef_, index=X.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
